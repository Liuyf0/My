## 1、OSI 的七层模型分别是？各自的功能是什么？

简要概括

* **物理层：底层数据传输，如网线；网卡标准。**
* **数据链路层：定义数据的基本格式，如何传输，如何标识；如网卡MAC地址。**
* **网络层：定义IP编址，定义路由功能；如不同设备的数据转发。**
* **传输层：端到端传输数据的基本功能；如 TCP、UDP。**
* **会话层：控制应用程序之间会话能力；如不同软件数据分发给不同软件。**
* **表示层：数据格式标识，基本压缩加密功能。**
* **应用层：各种应用软件，包括 Web 应用。**

说明

* **在四层，既传输层数据被称作****段**（Segments）；
* **三层网络层数据被称做****包**（Packages）；
* **二层数据链路层时数据被称为****帧**（Frames）；
* **一层物理层时数据被称为****比特流**（Bits）。

总结

* **网络七层模型是一个标准，而非实现。**
* **网络四层模型是一个实现的应用模型。**
* **网络四层模型由七层模型简化合并而来。**

## 2、说一下一次完整的HTTP请求过程包括哪些内容？

**域名解析 --> 发起TCP的3次握手 --> 建立TCP连接后发起http请求 --> 服务器响应http请求，浏览器得到html代码 --> 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） --> 浏览器对页面进行渲染呈现给用户。**

## 3、你知道DNS是什么？

**官方解释**：DNS（Domain Name System，域名系统），因特网上作为**域名和IP地址相互映射**的一个**分布式数据库**，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。

**通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。**

**通俗的讲**，我们更习惯于记住一个网站的名字，比如[www.baidu.com](www.baidu.com),而不是记住它的ip地址，比如：167.23.10.2。

## 4、DNS的工作原理？

**将主机域名转换为ip地址，属于应用层协议，使用UDP传输。（DNS应用层协议，以前有个考官问过）**

**
**过程：**
**总结： 浏览器缓存，系统缓存，路由器缓存，IPS服务器缓存，根域名服务器缓存，顶级域名服务器缓存，主域名服务器缓存。**
**一、主机向本地域名服务器的查询一般都是采用递归查询。**
**二、本地域名服务器向根域名服务器的查询的迭代查询。**
**1) 当用户输入域名时，浏览器先检查自己的缓存中是否包含这个域名映射的ip地址，有解析结束。**
**2）若没命中，则检查操作系统缓存（如Windows的hosts）中有没有解析过的结果，有解析结束。**
**3）若无命中，则请求本地域名服务器解析（LDNS）。**
**4）若LDNS没有命中就直接跳到根域名服务器请求解析。根域名服务器返回给LDNS一个 主域名服务器地址。**
**5）此时LDNS再发送请求给上一步返回的gTLD（ 通用顶级域）， 接受请求的gTLD查找并返回这个域名对应的Name Server的地址**
**6）Name Server根据映射关系表找到目标ip，返回给LDNS**
**7) LDNS缓存这个域名和对应的ip， 把解析的结果返回给用户，用户根据TTL值缓存到本地系统缓存中，域名解析过程至此结束

## 5、为什么域名解析用UDP协议？

**因为UDP快啊！UDP的DNS协议只要一个请求、一个应答就好了。**

**而使用基于TCP的DNS协议要三次握手、发送数据以及应答、四次挥手，但是UDP协议传输内容不能超过512字节。**

**不过客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。**

## 6、为什么区域传送用TCP协议？

**因为TCP协议可靠性好啊！**

**你要从主DNS上复制内容啊，你用不可靠的UDP？ 因为TCP协议传输的内容大啊，你用最大只能传512字节的UDP协议？万一同步的数据大于512字节，你怎么办？所以用TCP协议比较好！**

## 7、HTTP长连接和短连接的区别

**在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。**

**而从HTTP/1.1起，默认使用长连接，用以保持连接特性。**

## 8、什么是TCP粘包/拆包？发生的原因？

**一个完整的业务可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这个就是TCP的拆包和粘包问题。**

原因

**1、应用程序写入数据的字节大小大于套接字发送缓冲区的大小.**

**2、进行MSS大小的TCP分段。( MSS=TCP报文段长度-TCP首部长度)**

**3、以太网的payload大于MTU进行IP分片。（ MTU指：一种通信协议的某一层上面所能通过的最大数据包大小。）**

解决方案

**1、消息定长。**

**2、在包尾部增加回车或者空格符等特殊字符进行分割**

**3、将消息分为消息头和消息尾**

**4、使用其它复杂的协议，如RTMP协议等。**

## 9、为什么服务器会缓存这一项功能?如何实现的？

**原因**

* **缓解服务器压力；**
* **降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存服务器在地理位置上也有可能比源服务器来得近，例如浏览器缓存。**

**实现方法**

* **让代理服务器进行缓存；**
* **让客户端浏览器进行缓存。**

## 10、HTTP请求方法你知道多少？

**客户端发送的   ****请求报文**   第一行为请求行，包含了方法字段。

**根据 HTTP 标准，HTTP 请求可以使用多种请求方法。**

**HTTP1.0 定义了三种请求方法： GET, POST 和 HEAD方法。**

**HTTP1.1 新增了六种请求方法：OPTIONS、PUT、PATCH、DELETE、TRACE 和 CONNECT 方法。**

| **序  号** | **方法**    | **描述**                                                                                                                                     |
| ---------------- | ----------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| **1**      | **GET**     | **请求指定的页面信息，并返回实体主体。**                                                                                                     |
| **2**      | **HEAD**    | **类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头**                                                                          |
| **3**      | **POST**    | **向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。** |
| **4**      | **PUT**     | **从客户端向服务器传送的数据取代指定的文档的内容。**                                                                                         |
| **5**      | **DELETE**  | **请求服务器删除指定的页面。**                                                                                                               |
| **6**      | **CONNECT** | **HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。**                                                                                |
| **7**      | **OPTIONS** | **允许客户端查看服务器的性能。**                                                                                                             |
| **8**      | **TRACE**   | **回显服务器收到的请求，主要用于测试或诊断。**                                                                                               |
| **9**      | **PATCH**   | **是对 PUT 方法的补充，用来对已知资源进行局部更新 。**                                                                                       |

## 11、GET 和 POST 的区别，你知道哪些？

1. **get是获取数据，post是修改数据**
2. **get把请求的数据放在url上， 以?分割URL和传输数据，参数之间以&相连，所以get不太安全。而post把数据放在HTTP的包体内（request body  相对安全）**
3. **get提交的数据最大是2k（ 限制实际上取决于浏览器）， post理论上没有限制。**
4. **GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200(返回数据); POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)。**
5. **GET请求会被浏览器主动缓存，而POST不会，除非手动设置。**
6. **本质区别：GET是幂等的，而POST不是幂等的**
   > **这里的幂等性：幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。**
   >

**正因为它们有这样的区别，所以不应该且****不能用get请求做数据的增删改这些有副作用的操作**。因为get请求是幂等的，**在网络不好的隧道中会尝试重试**。如果用get请求增数据，会有**重复操作**的风险，而这种重复操作可能会导致副作用（浏览器和操作系统并不知道你会用get请求去做增操作）。

## 12、一个 TCP 连接中 HTTP 请求发送可以一起发送么（比如一起发三个请求，再三个响应一起接收）？

**HTTP/1.1 存在一个问题，单个 TCP 连接在同一时刻只能处理一个请求，意思是说：两个请求的生命周期不能重叠，任意两个 HTTP 请求从开始到结束的时间在同一个 TCP 连接里不能重叠。**

**在 HTTP/1.1 存在 Pipelining 技术可以完成这个多个请求同时发送，但是由于浏览器默认关闭，所以可以认为这是不可行的。在 HTTP2 中由于 Multiplexing 特点的存在，多个 HTTP 请求可以在同一个 TCP 连接中并行进行。**

**那么在 HTTP/1.1 时代，浏览器是如何提高页面加载效率的呢？主要有下面两点：**

* **维持和服务器已经建立的 TCP 连接，在同一连接上顺序处理多个请求。**
* **和服务器建立多个 TCP 连接。**

## 13、浏览器对同一 Host 建立 TCP 连接到的数量有没有限制？

**假设我们还处在 HTTP/1.1 时代，那个时候没有多路传输，当浏览器拿到一个有几十张图片的网页该怎么办呢？肯定不能只开一个 TCP 连接顺序下载，那样用户肯定等的很难受，但是如果每个图片都开一个 TCP 连接发 HTTP 请求，那电脑或者服务器都可能受不了，要是有 1000 张图片的话总不能开 1000 个TCP 连接吧，你的电脑同意 NAT 也不一定会同意。**

**有。Chrome 最多允许对同一个 Host 建立六个 TCP 连接。不同的浏览器有一些区别。**

**如果图片都是 HTTPS 连接并且在同一个域名下，那么浏览器在 SSL 握手之后会和服务器商量能不能用 HTTP2，如果能的话就使用 Multiplexing 功能在这个连接上进行多路传输。不过也未必会所有挂在这个域名的资源都会使用一个 TCP 连接去获取，但是可以确定的是 Multiplexing 很可能会被用到。**

**如果发现用不了 HTTP2 呢？或者用不了 HTTPS（现实中的 HTTP2 都是在 HTTPS 上实现的，所以也就是只能使用 HTTP/1.1）。那浏览器就会在一个 HOST 上建立多个 TCP 连接，连接数量的最大限制取决于浏览器设置，这些连接会在空闲的时候被浏览器用来发送新的请求，如果所有的连接都正在发送请求呢？那其他的请求就只能等等了。**

## 14、在浏览器地址栏输入一个URL后回车，背后会进行哪些技术步骤？

**1、查浏览器缓存，看看有没有已经缓存好的，如果没有**

**2 、检查本机host文件，**

**3、调用API，Linux下Socket函数 gethostbyname**

**4、向DNS服务器发送DNS请求，查询本地DNS服务器，这其中用的是UDP的协议**

**5、如果在一个子网内采用ARP地址解析协议进行ARP查询如果不在一个子网那就需要对默认网关进行DNS查询，如果还找不到会一直向上找根DNS服务器，直到最终拿到IP地址（全球400多个根DNS服务器，由13个不同的组织管理）**

**6、这个时候我们就有了服务器的IP地址 以及默认的端口号了，http默认是80 https是 443 端口号，会，首先尝试http然后调用Socket建立TCP连接，**

**7、经过三次握手成功建立连接后，开始传送数据，如果正是http协议的话，就返回就完事了，**

**8、如果不是http协议，服务器会返回一个5开头的的重定向消息，告诉我们用的是https，那就是说IP没变，但是端口号从80变成443了，好了，再四次挥手，完事，**

**9、再来一遍，这次除了上述的端口号从80变成443之外，还会采用SSL的加密技术来保证传输数据的安全性，保证数据传输过程中不被修改或者替换之类的，**

**10、这次依然是三次握手，沟通好双方使用的认证算法，加密和检验算法，在此过程中也会检验对方的CA安全证书。**

**11、确认无误后，开始通信，然后服务器就会返回你所要访问的网址的一些数据，在此过程中会将界面进行渲染，牵涉到ajax技术之类的，直到最后我们看到色彩斑斓的网页**

## 15、DNS负载均衡是什么策略？

**当一个网站有足够多的用户的时候，假如每次请求的资源都位于同一台机器上面，那么这台机器随时可能会崩掉。处理办法就是用DNS负载均衡技术，它的原理是在****DNS服务器中为同一个主机名配置多个IP地址,在应答DNS查询时,DNS服务器对每个查询将以DNS文件中主机记录的IP地址按顺序返回不同的解析结果,将客户端的访问引导到不同的机器上去,使得不同的客户端访问不同的服务器**,从而达到负载均衡的目的｡例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等。

## 16、HTTPS和HTTP的区别

**1、HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全， HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。**

**2、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。**
**3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。**

## 17、什么是SSL/TLS ？

**SSL代表安全套接字层。它是一种用于加密和验证应用程序（如浏览器）和Web服务器之间发送的数据的协议。 身份验证 ， 加密Https的加密机制是一种共享密钥加密和公开密钥加密并用的混合加密机制。**

**SSL/TLS协议作用：认证用户和服务，加密数据，维护数据的完整性的应用层协议加密和解密需要两个不同的密钥，故被称为非对称加密；加密和解密都使用同一个密钥的**

** 对称加密：优点在于加密、解密效率通常比较高 ，HTTPS 是基于非对称加密的， 公钥是公开的，**

## 18、HTTPS是如何保证数据传输的安全，整体的流程是什么？（SSL是怎么工作保证安全的）

**（1）客户端向服务器端发起SSL连接请求；**
**（2） 服务器把公钥发送给客户端，并且服务器端保存着唯一的私钥**
**（3）客户端用公钥对双方通信的对称秘钥进行加密，并发送给服务器端**
**（4）服务器利用自己唯一的私钥对客户端发来的对称秘钥进行解密，**
**（5）进行数据传输，服务器和客户端双方用公有的相同的对称秘钥对数据进行加密解密，可以保证在数据收发过程中的安全，即是第三方获得数据包，也无法对其进行加密，解密和篡改。**

**因为数字签名、摘要是证书防伪非常关键的武器。 “摘要”就是对传输的内容，通过hash算法计算出一段固定长度的串。然后，通过发送方的私钥对这段摘要进行加密，加密后得到的结果就是“数字签名”**

**SSL/TLS协议的基本思路是采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。**

**补充**：SSL/TLS的四次握手，目前网上的主流答案都在重复阮一峰老师的博客，属于TLS 1.0版本的答案，使用RSA密钥交换算法。但是现在TLS 1.2已经成为主流，使用ECDHE算法，如果面试可以说出这个版本的答案，应该会更好。

## 19、如何保证公钥不被篡改？

**将公钥放在数字证书中。只要证书是可信的，公钥就是可信的。**
**公钥加密计算量太大，如何减少耗用的时间？**
**每一次对话（session），客户端和服务器端都生成一个"对话密钥"（session key），用它来加密信息。由于"对话密钥"是对称加密，所以运算速度非常快，而服务器公钥只用于加密"对话密钥"本身，这样就减少了加密运算的消耗时间。**
**（1） 客户端向服务器端索要并验证公钥。**
**（2） 双方协商生成"对话密钥"。**
**（3） 双方采用"对话密钥"进行加密通信。上面过程的前两步，又称为"握手阶段"（handshake）。**

## 20、HTTP请求和响应报文有哪些主要字段？

请求报文

* **请求行：Request Line**
* **请求头：Request Headers**
* **请求体：Request Body**

响应报文

* **状态行：Status Line**
* **响应头：Response Headers**
* **响应体：Response Body**

## 21、Cookie是什么？

**HTTP 协议是****无状态**的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务，HTTP/1.1 引入 Cookie 来保存状态信息。

**Cookie 是****服务器发送到用户浏览器并保存在本地的一小块数据**，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。

**Cookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。**

**新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存储）或 IndexedDB。**

**cookie 的出现是因为 HTTP 是无状态的一种协议，换句话说，服务器记不住你，可能你每刷新一次网页，就要重新输入一次账号密码进行登录。这显然是让人无法接受的，cookie 的作用就好比服务器给你贴个标签，然后你每次向服务器再发请求时，服务器就能够 cookie 认出你。**

**抽象地概括一下：一个 cookie 可以认为是一个「变量」，形如 name=value，存储在浏览器；一个 session 可以理解为一种数据结构，多数情况是「映射」（键值对），存储在服务器上。**

## 22、Cookie有什么用途？用途

* **会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）**
* **个性化设置（如用户自定义设置、主题等）**
* **浏览器行为跟踪（如跟踪分析用户行为等）**

## 23、Session知识大总结

**除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。**

**Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。**

**使用 Session 维护用户登录状态的过程如下：**

1. **用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；**
2. **服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；**
3. **服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中；**
4. **客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。**

> **注意：Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。**

## 24、Session 的工作原理是什么？

**session 的工作原理是客户端登录完成之后，服务器会创建对应的 session，session 创建完之后，会把 session 的 id 发送给客户端，客户端再存储到浏览器中。这样客户端每次访问服务器时，都会带着 sessionid，服务器拿到 sessionid 之后，在内存找到与之对应的 session 这样就可以正常工作了。**

## 25、Cookie与Session的对比

**HTTP作为无状态协议，必然需要在某种方式保持连接状态。这里简要介绍一下Cookie和Session。**

* ##### Cookie

  **Cookie是客户端保持状态的方法。**

  **Cookie简单的理解就是存储由服务器发至客户端并由客户端保存的一段字符串。为了保持会话，服务器可以在响应客户端请求时将Cookie字符串放在Set-Cookie下，客户机收到Cookie之后保存这段字符串，之后再请求时候带上Cookie就可以被识别。**

  **除了上面提到的这些，Cookie在客户端的保存形式可以有两种，一种是会话Cookie一种是持久Cookie，会话Cookie就是将服务器返回的Cookie字符串保持在内存中，关闭浏览器之后自动销毁，持久Cookie则是存储在客户端磁盘上，其有效时间在服务器响应头中被指定，在有效期内，客户端再次请求服务器时都可以直接从本地取出。需要说明的是，存储在磁盘中的Cookie是可以被多个浏览器代理所共享的。**
* **Session**
  **Session是服务器保持状态的方法。**
  **首先需要明确的是，Session保存在服务器上，可以保存在数据库、文件或内存中，每个用户有独立的Session用户在客户端上记录用户的操作。我们可以理解为每个用户有一个独一无二的Session ID作为Session文件的Hash键，通过这个值可以锁定具体的Session结构的数据，这个Session结构中存储了用户操作行为。**

**当服务器需要识别客户端时就需要结合Cookie了。每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端。实际上大多数的应用都是用Cookie来实现Session跟踪的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在Cookie里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。如果客户端的浏览器禁用了Cookie，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如sid=xxxxx这样的参数，服务端据此来识别用户，这样就可以帮用户完成诸如用户名等信息自动填入的操作了。**

## 26、SQL注入攻击了解吗？

**攻击者在HTTP请求中注入恶意的SQL代码，服务器使用参数构建数据库SQL命令时，恶意SQL被一起构造，并在数据库中执行。**
**用户登录，输入用户名 lianggzone，密码 ‘ or ‘1’=’1 ，如果此时使用参数构造的方式，就会出现**
**select * from user where name = ‘lianggzone’ and password = ‘’ or ‘1’=‘1’**
**不管用户名和密码是什么内容，使查询出来的用户列表不为空。如何防范SQL注入攻击使用预编译的PrepareStatement是必须的，但是一般我们会从两个方面同时入手。**
**Web端**
**1）有效性检验。**
**2）限制字符串输入的长度。**
**服务端**
**1）不用拼接SQL字符串。**
**2）使用预编译的PrepareStatement。**
**3）有效性检验。(为什么服务端还要做有效性检验？第一准则，外部都是不可信的，防止攻击者绕过Web端请求)**
**4）过滤SQL需要的参数中的特殊字符。比如单引号、双引号。**

## 27、什么是RARP？工作原理

**概括： 反向地址转换协议，网络层协议，RARP与ARP工作方式相反。 RARP使只知道自己硬件地址的主机能够知道其IP地址。RARP发出要反向解释的物理地址并希望返回其IP地址，应答包括能够提供所需信息的RARP服务器发出的IP地址。**
**原理：**
**(1)网络上的每台设备都会有一个独一无二的硬件地址，通常是由设备厂商分配的MAC地址。主机从网卡上读取MAC地址，然后在网络上发送一个RARP请求的广播数据包，请求RARP服务器回复该主机的IP地址。**

**(2)RARP服务器收到了RARP请求数据包，为其分配IP地址，并将RARP回应发送给主机。**

**(3)PC1收到RARP回应后，就使用得到的IP地址进行通讯。**

## 28、端口有效范围是多少到多少？

**0-1023为知名端口号，比如其中HTTP是80，FTP是20（数据端口）、21（控制端口）**

**UDP和TCP报头使用两个字节存放端口号，所以端口号的有效范围是从0到65535。动态端口的范围是从1024到65535**

## 29、HTTP中缓存的私有和共有字段？知道吗？

**private 指令规定了将资源作为私有缓存，只能被单独用户使用，一般存储在用户浏览器中。**

```
Cache-Control: private
```

**public 指令规定了将资源作为公共缓存，可以被多个用户使用，一般存储在代理服务器中。**

```
Cache-Control: public
```

## 30、GET 方法参数写法是固定的吗？

**在约定中，我们的参数是写在 ? 后面，用 & 分割。**

**我们知道，解析报文的过程是通过获取 TCP 数据，用正则等工具从数据中获取 Header 和 Body，从而提取参数。**

**比如header请求头中添加token，来验证用户是否登录等权限问题。**

**也就是说，我们可以自己约定参数的写法，只要服务端能够解释出来就行，万变不离其宗。**

## 31、GET 方法的长度限制是怎么回事？

**网络上都会提到浏览器地址栏输入的参数是有限的。**

**首先说明一点，HTTP 协议没有 Body 和 URL 的长度限制，对 URL 限制的大多是浏览器和服务器的原因。**

**浏览器原因就不说了，服务器是因为处理长 URL 要消耗比较多的资源，为了性能和安全（防止恶意构造长 URL 来攻击）考虑，会给 URL 长度加限制。**

## 32、POST 方法比 GET 方法安全？

**有人说POST 比 GET 安全，因为数据在地址栏上不可见。**

**然而，从传输的角度来说，他们都是不安全的，因为 HTTP 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文。**

**要想安全传输，就只有加密，也就是 HTTPS。**

## 33、POST 方法会产生两个 TCP 数据包？你了解吗？

**有些文章中提到，POST 会将 header 和 body 分开发送，先发送 header，服务端返回 100 状态码再发送 body。**

**HTTP 协议中没有明确说明 POST 会产生两个 TCP 数据包，而且实际测试(Chrome)发现，header 和 body 不会分开发送。**

**所以，header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为。**

## 34、Session和cookie应该如何去选择（适用场景）？

* **Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session；**
* **Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密；**
* **对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。**

## 35、DDos 攻击了解吗？

**客户端向服务端发送请求链接数据包，服务端向客户端发送确认数据包，客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认**
**没有彻底根治的办法，除非不使用TCP**
**DDos 预防：**
**1）限制同时打开SYN半链接的数目**
**2）缩短SYN半链接的Time out 时间**
**3）关闭不必要的服务**

## 36、MTU和MSS分别是什么？

**MTU：maximum transmission unit，最大传输单元，由硬件规定，如以太网的MTU为1500字节。**

**MSS：maximum segment size，最大分节大小，为TCP数据包每次传输的最大数据分段大小，一般由发送端向对端TCP通知对端在每个分节中能发送的最大TCP数据。MSS值为MTU值减去IPv4 Header（20 Byte）和TCP header（20 Byte）得到。**

## 37、HTTP中有个缓存机制，但如何保证缓存是最新的呢？（缓存过期机制）

**max-age 指令出现在请求报文，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。**

**max-age 指令出现在响应报文，表示缓存资源在缓存服务器中保存的时间。**

```
Cache-Control: max-age=31536000
```

**Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期。**

```
Expires: Wed, 04 Jul 2012 08:26:05 GMT
```

* **在 HTTP/1.1 中，会优先处理 max-age 指令；**
* **在 HTTP/1.0 中，max-age 指令会被忽略掉。**

## 38、TCP头部中有哪些信息？

* **序号（32bit）：传输方向上字节流的字节编号。初始时序号会被设置一个随机的初始值（ISN），之后每次发送数据时，序号值 = ISN + 数据在整个字节流中的偏移。假设A -> B且ISN = 1024，第一段数据512字节已经到B，则第二段数据发送时序号为1024 + 512。用于解决网络包乱序问题。**
* **确认号（32bit）：接收方对发送方TCP报文段的响应，其值是收到的序号值 + 1。**
* **首部长（4bit）：标识首部有多少个4字节 * 首部长，最大为15，即60字节。**
* **标志位（6bit）：**
  * **URG：标志紧急指针是否有效。**
  * **ACK：标志确认号是否有效（确认报文段）。用于解决丢包问题。**
  * **PSH：提示接收端立即从缓冲读走数据。**
  * **RST：表示要求对方重新建立连接（复位报文段）。**
  * **SYN：表示请求建立一个连接（连接报文段）。**
  * **FIN：表示关闭连接（断开报文段）。**
* **窗口（16bit）：接收窗口。用于告知对方（发送方）本方的缓冲还能接收多少字节数据。用于解决流控。**
* **校验和（16bit）：接收端用CRC检验整个报文段有无损坏。**

## 39、常见TCP的连接状态有哪些？

* **CLOSED：初始状态。**
* **LISTEN：服务器处于监听状态。**
* **SYN_SEND：客户端socket执行CONNECT连接，发送SYN包，进入此状态。**
* **SYN_RECV：服务端收到SYN包并发送服务端SYN包，进入此状态。**
* **ESTABLISH：表示连接建立。客户端发送了最后一个ACK包后进入此状态，服务端接收到ACK包后进入此状态。**
* **FIN_WAIT_1：终止连接的一方（通常是客户机）发送了FIN报文后进入。等待对方FIN。**
* **CLOSE_WAIT：（假设服务器）接收到客户机FIN包之后等待关闭的阶段。在接收到对方的FIN包之后，自然是需要立即回复ACK包的，表示已经知道断开请求。但是本方是否立即断开连接（发送FIN包）取决于是否还有数据需要发送给客户端，若有，则在发送FIN包之前均为此状态。**
* **FIN_WAIT_2：此时是半连接状态，即有一方要求关闭连接，等待另一方关闭。客户端接收到服务器的ACK包，但并没有立即接收到服务端的FIN包，进入FIN_WAIT_2状态。**
* **LAST_ACK：服务端发动最后的FIN包，等待最后的客户端ACK响应，进入此状态。**
* **TIME_WAIT：客户端收到服务端的FIN包，并立即发出ACK包做最后的确认，在此之后的2MSL时间称为TIME_WAIT状态。**

## 40、应用层常见协议知道多少？了解几个？

| **协议**   | **名称**                       | **默认端口**       | **底层协议**                                                            |
| ---------------- | ------------------------------------ | ------------------------ | ----------------------------------------------------------------------------- |
| **HTTP**   | **超文本传输协议**             | **80**             | **TCP**                                                                 |
| **HTTPS**  | **超文本传输安全协议**         | **443**            | **TCP**                                                                 |
| **Telnet** | **远程登录服务的标准协议**     | **23**             | **TCP**                                                                 |
| **FTP**    | **文件传输协议**               | **20传输和21连接** | **TCP**                                                                 |
| **TFTP**   | **简单文件传输协议**           | **69**             | **UDP**                                                                 |
| **SMTP**   | **简单邮件传输协议（发送用）** | **25**             | **TCP**                                                                 |
| **POP**    | **邮局协议（接收用）**         | **110**            | **TCP**                                                                 |
| **DNS**    | **域名解析服务**               | **53**             | **服务器间进行域传输的时候用TCP** **客户端查询DNS服务器时用 UDP** |

> **感谢网友勘误”TFTP简单文件传输协议 初始默认端口号69“，已修正，2021.10.12**[https://github.com/forthespada/InterviewGuide/issues/13](https://github.com/forthespada/InterviewGuide/issues/13)

## 41、浏览器在与服务器建立了一个 TCP 连接后是否会在一个 HTTP 请求完成后断开？什么情况下会断开？

**在 HTTP/1.0 中，一个服务器在发送完一个 HTTP 响应后，会断开 TCP 链接。但是这样每次请求都会重新建立和断开 TCP 连接，代价过大。所以虽然标准中没有设定，****某些服务器对 Connection: keep-alive 的 Header 进行了支持**。意思是说，完成这个 HTTP 请求之后，不要断开 HTTP 请求使用的 TCP 连接。这样的好处是连接可以被重新使用，之后发送 HTTP 请求的时候不需要重新建立 TCP 连接，以及如果维持连接，那么 SSL 的开销也可以避免。

**持久连接**：既然维持 TCP 连接好处这么多，HTTP/1.1 就把 Connection 头写进标准，并且默认开启持久连接，除非请求中写明 Connection: close，那么浏览器和服务器之间是会维持一段时间的 TCP 连接，不会一个请求结束就断掉。

**默认情况下建立 TCP 连接不会断开，只有在请求报头中声明 Connection: close 才会在请求完成后关闭连接。**

## 42、三次握手相关内容

**三次握手（Three-way Handshake）其实就是指建立一个TCP连接时，需要客户端和服务器总共发送3个包。进行三次握手的主要作用就是为了确认双方的接收能力和发送能力是否正常、指定自己的初始化序列号为后面的可靠性传送做准备。实质上其实就是连接服务器指定端口，建立TCP连接，并同步连接双方的序列号和确认号，交换** `TCP窗口大小`信息。

**初始状态**：客户端处于 `closed(关闭)`状态，服务器处于 `listen(监听)` 状态。

* **第一次握手**：客户端发送请求报文将 `SYN = 1`同步序列号和初始化序列号 `seq = x`发送给服务端，发送完之后客户端处于 `SYN_Send`状态。（验证了客户端的发送能力和服务端的接收能力）
* **第二次握手**：服务端受到 `SYN` 请求报文之后，如果同意连接，会以自己的同步序列号 `SYN(服务端) = 1`、初始化序列号 `seq = y`和确认序列号（期望下次收到的数据包）`ack = x+ 1` 以及确认号 `ACK = 1`报文作为应答，服务器为 `SYN_Receive`状态。（问题来了，两次握手之后，站在客户端角度上思考：我发送和接收都ok，服务端的发送和接收也都ok。但是站在服务端的角度思考：哎呀，我服务端接收ok，但是我不清楚我的发送ok不ok呀，而且我还不知道你接受能力如何呢？所以老哥，你需要给我三次握手来传个话告诉我一声。你要是不告诉我，万一我认为你跑了，然后我可能出于安全性的考虑继续给你发一次，看看你回不回我。）
* **第三次握手**： 客户端接收到服务端的 `SYN + ACK`之后，知道可以下次可以发送了下一序列的数据包了，然后发送同步序列号 `ack = y + 1`和数据包的序列号 `seq = x + 1`以及确认号 `ACK = 1`确认包作为应答，客户端转为 `established`状态。（分别站在双方的角度上思考，各自ok）

## 43、为什么需要三次握手，两次不行吗？

**弄清这个问题，我们需要先弄明白三次握手的目的是什么，能不能只用两次握手来达到同样的目的。**

* **第一次握手：客户端发送网络包，服务端收到了。 这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。**
* **第二次握手：服务端发包，客户端收到了。 这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。**
* **第三次握手：客户端发包，服务端收到了。 这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。**

**因此，需要三次握手才能确认双方的接收与发送能力是否正常。**

**试想如果是用两次握手，则会出现下面这种情况：**

> **如客户端发出连接请求，但因连接请求报文丢失而未收到确认，于是客户端再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接，客户端共发出了两个连接请求报文段，其中第一个丢失，第二个到达了服务端，但是第一个丢失的报文段只是在****某些网络结点长时间滞留了，延误到连接释放以后的某个时间才到达服务端**，此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，不采用三次握手，只要服务端发出确认，就建立新的连接了，此时客户端忽略服务端发来的确认，也不发送数据，则服务端一致等待客户端发送数据，浪费资源。

## 44、什么是半连接队列？

**服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个****队列**里，我们把这种队列称之为**半连接队列**。

**当然还有一个****全连接队列**，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。

**这里在补充一点关于****SYN-ACK 重传次数**的问题： 服务器发送完SYN-ACK包，如果未收到客户确认包，服务器进行首次重传，等待一段时间仍未收到客户确认包，进行第二次重传。如果重传次数超过系统规定的最大重传次数，系统将该连接信息从半连接队列中删除。 注意，每次重传等待的时间不一定相同，一般会是指数增长，例如间隔时间为 1s，2s，4s，8s......

## 45、 ISN(Initial Sequence Number)是固定的吗？

**当一端为建立连接而发送它的SYN时，它为连接选择一个初始序号。ISN随时间而变化，因此每个连接都将具有不同的ISN，ISN是一个有可以看作是一个32比特的计数器，但并不是简单的计数器，大概每4ms加1 。**

> **ISN = M + F(localhost, localport, remotehost, remoteport)(M为计数器)，ISN应该由这个公式确定，F为哈希算法，不是一个简单计数器。**

**这样选择序号的目的在于防止在网络中被延迟的分组在以后又被传送，而导致某个连接的一方对它做错误的解释。**

**三次握手的其中一个重要功能是客户端和服务端交换 ISN(Initial Sequence Number)，以便让对方知道接下来接收数据的时候如何按序列号组装数据。如果 ISN 是固定的，攻击者很容易猜出后续的确认号，因此 ISN 是动态生成的。**

## 46、SYN攻击是什么？

**服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的**，所以服务器容易受到SYN洪泛攻击。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server则回复确认包，并等待Client确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击。

**检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。在 Linux/Unix 上可以使用系统自带的 netstats 命令来检测 SYN 攻击。**

```
netstat -n -p TCP | grep SYN_RECV
复制代码
```

**常见的防御 SYN 攻击的方法有如下几种：**

* **缩短超时（SYN Timeout）时间**
* **增加最大半连接数**
* **过滤网关防护**
* **SYN cookies技术**

## 47、 四次挥手相关内容

**建立一个连接需要三次握手，而终止一个连接要经过四次挥手（也有将四次挥手叫做四次握手的）。这由TCP的****半关闭**（half-close）造成的。所谓的半关闭，其实就是TCP提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力。

**TCP 的连接的拆除需要发送四个包，因此称为四次挥手(Four-way handshake)，客户端或服务器均可主动发起挥手动作。**

**刚开始双方都处于 ESTABLISHED 状态，假如是客户端先发起关闭请求。四次挥手的过程如下：**

* **第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于 **`FIN_WAIT1` 状态。 即发出**连接释放报文段**（FIN=1，序号seq=u），并停止再发送数据，主动关闭TCP连接，进入FIN_WAIT1（终止等待1）状态，等待服务端的确认。
* **第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 +1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 **`CLOSE_WAIT` 状态。 即服务端收到连接释放报文段后即发出**确认报文段**（ACK=1，确认号ack=u+1，序号seq=v），服务端进入CLOSE_WAIT（关闭等待）状态，此时的TCP处于半关闭状态，客户端到服务端的连接释放。客户端收到服务端的确认后，进入FIN_WAIT2（终止等待2）状态，等待服务端发出的连接释放报文段。
* **第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 **`LAST_ACK` 的状态。 即服务端没有要向客户端发出的数据，服务端发出**连接释放报文段**（FIN=1，ACK=1，序号seq=w，确认号ack=u+1），服务端进入LAST_ACK（最后确认）状态，等待客户端的确认。
* **第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 +1 作为自己 ACK 报文的确认号值，此时客户端处于 **`TIME_WAIT` 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态，服务端收到 ACK 报文之后，就处于关闭连接了，处于 `CLOSED` 状态。 即客户端收到服务端的连接释放报文段后，对此发出**确认报文段**（ACK=1，seq=u+1，ack=w+1），客户端进入TIME_WAIT（时间等待）状态。此时TCP未释放掉，需要经过时间等待计时器设置的时间2MSL后，客户端才进入CLOSED状态。

**收到一个FIN只意味着在这一方向上没有数据流动。****客户端执行主动关闭并进入TIME_WAIT是正常的，服务端通常执行被动关闭，不会进入TIME_WAIT状态。**

**在socket编程中，任何一方执行close()操作即可产生挥手操作。 **

## 48、四次挥手释放连接时，等待2MSL的意义?

> **MSL**是Maximum Segment Lifetime的英文缩写，可译为“最长报文段寿命”，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

**为了保证客户端发送的最后一个ACK报文段能够到达服务器。因为这个ACK有可能丢失，从而导致处在LAST-ACK状态的服务器收不到对FIN-ACK的确认报文。服务器会超时重传这个FIN-ACK，接着客户端再重传一次确认，重新启动时间等待计时器。最后客户端和服务器都能正常的关闭。假设客户端不等待2MSL，而是在发送完ACK之后直接释放关闭，一但这个ACK丢失的话，服务器就无法正常的进入关闭连接状态。**

1. **保证客户端发送的最后一个ACK报文段能够到达服务端。 这个ACK报文段有可能丢失，使得处于LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认，服务端超时重传FIN+ACK报文段，而客户端能在2MSL时间内收到这个重传的FIN+ACK报文段，接着客户端重传一次确认，重新启动2MSL计时器，最后客户端和服务端都进入到CLOSED状态，若客户端在TIME-WAIT状态不等待一段时间，而是发送完ACK报文段后立即释放连接，则无法收到服务端重传的FIN+ACK报文段，所以不会再发送一次确认报文段，则服务端无法正常进入到CLOSED状态。**
2. **防止“已失效的连接请求报文段”出现在本连接中。 客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。**

## 49、对称密钥加密的优点缺点？

**对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。**

* **优点：运算速度快**
* **缺点：无法安全地将密钥传输给通信方**

## 50、HTTPS采用的加密方式有哪些？是对称还是非对称？

**HTTPS 采用混合的加密机制，使用****非对称密钥加密用于传输对称密钥来保证传输过程的安全性**，之后使用**对称密钥加密进行通信来保证通信过程的效率**。

**确保传输安全过程（其实就是rsa原理）：**

1. **Client给出协议版本号、一个客户端生成的随机数（Client random），以及客户端支持的加密方法。**
2. **Server确认双方使用的加密方法，并给出数字证书、以及一个服务器生成的随机数（Server random）。**
3. **Client确认数字证书有效，然后生成呀一个新的随机数（Premaster secret），并使用数字证书中的公钥，加密这个随机数，发给Server。**
4. **Server使用自己的私钥，获取Client发来的随机数（Premaster secret）。**
5. **Client和Server根据约定的加密方法，使用前面的三个随机数，生成”对话密钥”（session key），用来加密接下来的整个对话过程。**

## 51、为什么有的时候刷新页面不需要重新建立 SSL 连接？

**TCP 连接有的时候会被浏览器和服务端维持一段时间，TCP 不需要重新建立，SSL 自然也会用之前的。**

## 52、SSL中的认证中的证书是什么？了解过吗？

**通过使用 ****证书** 来对通信方进行认证。

**数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。**

**服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。**

**进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。**

## 53、HTTP如何禁用缓存？如何确认缓存？

**HTTP/1.1 通过 Cache-Control 首部字段来控制缓存。**

**禁止进行缓存**

**no-store 指令规定不能对请求或响应的任何一部分进行缓存。**

```
Cache-Control: no-store
```

**强制确认缓存**

**no-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效时才能使用该缓存对客户端的请求进行响应。**

```
Cache-Control: no-cache
```

## 54、GET与POST传递数据的最大长度能够达到多少呢？

**get 是通过URL提交数据，因此GET可提交的数据量就跟URL所能达到的最大长度有直接关系。**

**很多文章都说GET方式提交的数据最多只能是1024字节，而实际上，URL不存在参数上限的问题，HTTP协议规范也没有对URL长度进行限制。**

**这个限制是特定的浏览器及服务器对它的限制，比如IE对URL长度的限制是2083字节(2K+35字节)。对于其他浏览器，如FireFox，Netscape等，则没有长度限制，这个时候其限制取决于服务器的操作系统；即如果url太长，服务器可能会因为安全方面的设置从而拒绝请求或者发生不完整的数据请求。**

**post 理论上讲是没有大小限制的，HTTP协议规范也没有进行大小限制，但实际上post所能传递的数据量大小取决于服务器的设置和内存大小。**

**因为我们一般post的数据量很少超过MB的，所以我们很少能感觉的到post的数据量限制，但实际中如果你上传文件的过程中可能会发现这样一个问题，即上传个头比较大的文件到服务器时候，可能上传不上去。**

**以php语言来说，查原因的时候你也许会看到有说PHP上传文件涉及到的参数PHP默认的上传有限定，一般这个值是2MB，更改这个值需要更改php.conf的post_max_size这个值。这就很明白的说明了这个问题了。**

## 55、网络层常见协议？可以说一下吗？

| **协议** | **名称**                 | **作用**                                                                                                                           |
| -------------- | ------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------- |
| **IP**   | **网际协议**             | **IP协议不但定义了数据传输时的基本单元和格式，还定义了数据报的递交方法和路由选择**                                                 |
| **ICMP** | **Internet控制报文协议** | **ICMP就是一个“错误侦测与回报机制”，其目的就是让我们能够检测网路的连线状况﹐也能确保连线的准确性，是ping和traceroute的工作协议** |
| **RIP**  | **路由信息协议**         | **使用“跳数”(即metric)来衡量到达目标地址的路由距离**                                                                             |
| **IGMP** | **Internet组管理协议**   | **用于实现组播、广播等通信**                                                                                                       |

## 56、TCP四大拥塞控制算法总结？（极其重要）

### **四大算法**

**拥塞控制主要是四个算法：1）慢启动，2）拥塞避免，3）拥塞发生，4）快速恢复。这四个算法不是一天都搞出来的，这个四算法的发展经历了很多时间，到今天都还在优化中。**

### 慢热启动算法 – Slow Start

** 所谓慢启动，也就是TCP连接刚建立，一点一点地提速，试探一下网络的承受能力，以免直接扰乱了网络通道的秩序。**

** 慢启动算法：**

**1) 连接建好的开始先初始化拥塞窗口cwnd大小为1，表明可以传一个MSS大小的数据。**
**2) 每当收到一个ACK，cwnd大小加一，呈线性上升。**
**3) 每当过了一个往返延迟时间RTT(Round-Trip Time)，cwnd大小直接翻倍，乘以2，呈指数让升。**
**4) 还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”（后面会说这个算法）**

### 拥塞避免算法 – Congestion Avoidance

** 如同前边说的，当拥塞窗口大小cwnd大于等于慢启动阈值ssthresh后，就进入拥塞避免算法。算法如下：**

**1) 收到一个ACK，则cwnd = cwnd + 1 / cwnd**
**2) 每当过了一个往返延迟时间RTT，cwnd大小加一。**

** 过了慢启动阈值后，拥塞避免算法可以避免窗口增长过快导致窗口拥塞，而是缓慢的增加调整到网络的最佳值。**

### 拥塞发生状态时的算法

** 一般来说，TCP拥塞控制默认认为网络丢包是由于网络拥塞导致的，所以一般的TCP拥塞控制算法以丢包为网络进入拥塞状态的信号。对于丢包有两种判定方式，一种是超时重传RTO[Retransmission Timeout]超时，另一个是收到三个重复确认ACK。**

** 超时重传是TCP协议保证数据可靠性的一个重要机制，其原理是在发送一个数据以后就开启一个计时器，在一定时间内如果没有得到发送数据报的ACK报文，那么就重新发送数据，直到发送成功为止。**

** 但是如果发送端接收到3个以上的重复ACK，TCP就意识到数据发生丢失，需要重传。这个机制不需要等到重传定时器超时，所以叫**
**做快速重传，而快速重传后没有使用慢启动算法，而是拥塞避免算法，所以这又叫做快速恢复算法。**

** 超时重传RTO[Retransmission Timeout]超时，TCP会重传数据包。TCP认为这种情况比较糟糕，反应也比较强烈：**

* **由于发生丢包，将慢启动阈值ssthresh设置为当前cwnd的一半，即ssthresh = cwnd / 2.**
* **cwnd重置为1**
* **进入慢启动过程**

** 最为早期的TCP Tahoe算法就只使用上述处理办法，但是由于一丢包就一切重来，导致cwnd又重置为1，十分不利于网络数据的稳定传递。**

** 所以，TCP Reno算法进行了优化。当收到三个重复确认ACK时，TCP开启快速重传Fast Retransmit算法，而不用等到RTO超时再进行重传：**

* **cwnd大小缩小为当前的一半**
* **ssthresh设置为缩小后的cwnd大小**
* **然后进入快速恢复算法Fast Recovery。**

### 快速恢复算法 – Fast Recovery

** TCP Tahoe是早期的算法，所以没有快速恢复算法，而Reno算法有。在进入快速恢复之前，cwnd和ssthresh已经被更改为原有cwnd的一半。快速恢复算法的逻辑如下：**

* **cwnd = cwnd + 3 ***MSS，加3* MSS的原因是因为收到3个重复的ACK。
* **重传DACKs指定的数据包。**
* **如果再收到DACKs，那么cwnd大小增加一。**
* **如果收到新的ACK，表明重传的包成功了，那么退出快速恢复算法。将cwnd设置为ssthresh，然后进入拥塞避免算法。**

** 如图所示，第五个包发生了丢失，所以导致接收方接收到三次重复ACK，也就是ACK5。所以将ssthresh设置当当时cwnd的一半，也就是6/2 = 3，cwnd设置为3 + 3 = 6。然后重传第五个包。当收到新的ACK时，也就是ACK11，则退出快速恢复阶段，将cwnd重新设置为当前的ssthresh，也就是3，然后进入拥塞避免算法阶段。**

## 57、为何快速重传是选择3次ACK？

**主要的考虑还是要区分包的丢失是由于链路故障还是乱序等其他因素引发。**

**两次duplicated ACK时很可能是乱序造成的！三次duplicated ACK时很可能是丢包造成的！四次duplicated ACK更更更可能是丢包造成的，但是这样的响应策略太慢。丢包肯定会造成三次duplicated ACK!综上是选择收到三个重复确认时窗口减半效果最好，这是实践经验。**

**在没有fast retransmit / recovery 算法之前，重传依靠发送方的retransmit timeout，就是在timeout内如果没有接收到对方的ACK，默认包丢了，发送方就重传，包的丢失原因。**

**1）包checksum 出错 **

**2）网络拥塞 **

**3）网络断，包括路由重收敛，但是发送方无法判断是哪一种情况，于是采用最笨的办法，就是将自己的发送速率减半，即CWND 减为1/2，这样的方法对2是有效的，可以缓解网络拥塞，3则无所谓，反正网络断了，无论发快发慢都会被丢；但对于1来说，丢包是因为偶尔的出错引起，一丢包就对半减速不合理。**

**于是有了fast retransmit 算法，基于在反向还可以接收到ACK，可以认为网络并没有断，否则也接收不到ACK，如果在timeout 时间内没有接收到> 2 的duplicated ACK，则概率大事件为乱序，乱序无需重传，接收方会进行排序工作；**

**而如果接收到三个或三个以上的duplicated ACK，则大概率是丢包，可以逻辑推理，发送方可以接收ACK，则网络是通的，可能是1、2造成的，先不降速，重传一次，如果接收到正确的ACK，则一切OK，流速依然（包出错被丢）。**

**而如果依然接收到duplicated ACK，则认为是网络拥塞造成的，此时降速则比较合理。**

## 58、你了解流量控制原理吗？

* **目的是接收方通过TCP头窗口字段告知发送方本方可接收的最大数据量，用以解决发送速率过快导致接收方不能接收的问题。所以流量控制是点对点控制。**
* **TCP是双工协议，双方可以同时通信，所以发送方接收方各自维护一个发送窗和接收窗。**
  * **发送窗：用来限制发送方可以发送的数据大小，其中发送窗口的大小由接收端返回的TCP报文段中窗口字段来控制，接收方通过此字段告知发送方自己的缓冲（受系统、硬件等限制）大小。**
  * **接收窗：用来标记可以接收的数据大小。**
* **TCP是流数据，发送出去的数据流可以被分为以下四部分：已发送且被确认部分 | 已发送未被确认部分 | 未发送但可发送部分 | 不可发送部分，其中发送窗 = 已发送未确认部分 + 未发但可发送部分。接收到的数据流可分为：已接收 | 未接收但准备接收 | 未接收不准备接收。接收窗 = 未接收但准备接收部分。**
* **发送窗内数据只有当接收到接收端某段发送数据的ACK响应时才移动发送窗，左边缘紧贴刚被确认的数据。接收窗也只有接收到数据且最左侧连续时才移动接收窗口。**

## 59、建立TCP服务器的各个系统调用过程是怎样的？

* **服务器：**
  * **创建socket -> int socket(int domain, int type, int protocol);**

    * **domain：协议域，决定了socket的地址类型，IPv4为AF_INET。**
    * **type：指定socket类型，SOCK_STREAM为TCP连接。**
    * **protocol：指定协议。IPPROTO_TCP表示TCP协议，为0时自动选择type默认协议。**
  * **绑定socket和端口号 -> int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);**

    * **sockfd：socket返回的套接字描述符，类似于文件描述符fd。**
    * **addr：有个sockaddr类型数据的指针，指向的是被绑定结构变量。**

    ```
        // IPv4的sockaddr地址结构
        struct sockaddr_in {
            sa_family_t sin_family;    // 协议类型，AF_INET
            in_port_t sin_port;    // 端口号
            struct in_addr sin_addr;    // IP地址
        };
        struct in_addr {
            uint32_t s_addr;
        }
    ```

    * **addrlen：地址长度。**
  * **监听端口号 -> int listen(int sockfd, int backlog);**

    * **sockfd：要监听的sock描述字。**
    * **backlog：socket可以排队的最大连接数。**
  * **接收用户请求 -> int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);**

    * **sockfd：服务器socket描述字。**
    * **addr：指向地址结构指针。**
    * **addrlen：协议地址长度。**
    * **注：一旦accept某个客户机请求成功将返回一个全新的描述符用于标识具体客户的TCP连接。**
  * **从socket中读取字符 -> ssize_t read(int fd, void *buf, size_t count);**

    * **fd：连接描述字。**
    * **buf：缓冲区buf。**
    * **count：缓冲区长度。**
    * **注：大于0表示读取的字节数，返回0表示文件读取结束，小于0表示发生错误。**
  * **关闭socket -> int close(int fd);**

    * **fd：accept返回的连接描述字，每个连接有一个，生命周期为连接周期。**
    * **注：sockfd是监听描述字，一个服务器只有一个，用于监听是否有连接；fd是连接描述字，用于每个连接的操作。**
* **客户机：**
  * **创建socket -> int socket(int domain, int type, int protocol);**
  * **连接指定计算机 -> int connect(int sockfd, struct sockaddr* addr, socklen_t addrlen);**
    * **sockfd客户端的sock描述字。**
    * **addr：服务器的地址。**
    * **addrlen：socket地址长度。**
  * **向socket写入信息 -> ssize_t write(int fd, const void *buf, size_t count);**
    * **fd、buf、count：同read中意义。**
    * **大于0表示写了部分或全部数据，小于0表示出错。**
  * **关闭oscket -> int close(int fd);**
    * **fd：同服务器端fd。**

## 60、TCP 协议如何保证可靠传输？

* **确认和重传**：接收方收到报文就会确认，发送方发送一段时间后没有收到确认就会重传。
* **数据校验**：TCP报文头有校验和，用于校验报文是否损坏。
* **数据合理分片和排序**：tcp会按最大传输单元(MTU)合理分片，接收方会缓存未按序到达的数据，重新排序后交给应用层。而UDP：IP数据报大于1500字节，大于MTU。这个时候发送方的IP层就需要分片，把数据报分成若干片，是的每一片都小于MTU。而接收方IP层则需要进行数据报的重组。由于UDP的特性，某一片数据丢失时，接收方便无法重组数据报，导致丢弃整个UDP数据报。
* **流量控制**：当接收方来不及处理发送方的数据，能通过滑动窗口，提示发送方降低发送的速率，防止包丢失。
* **拥塞控制**：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失。

**原因**

**TCP协议中规定，TCP的首部字段中有一个字段是校验和，发送方将伪首部、TCP首部、TCP数据使用累加和校验的方式计算出一个数字，然后存放在首部的校验和字段里，接收者收到TCP包后重复这个过程，然后将计算出的校验和和接收到的首部中的校验和比较，如果不一致则说明数据在传输过程中出错。**

**这就是TCP的数据校验机制。 但是这个机制能够保证检查出一切错误吗？****显然不能**。

**因为这种校验方式是累加和，也就是将一系列的数字（TCP协议规定的是数据中的每16个比特位数据作为一个数字）求和后取末位。 但是小学生都知道A+B=B+A，假如在传输的过程中有前后两个16比特位的数据前后颠倒了（至于为什么这么巧合？我不知道，也许路由器有bug？也许是宇宙中的高能粒子击中了电缆？反正这个事情的概率不为零，就有可能会发生），那么校验和的计算结果和颠倒之前是一样的，那么接收端肯定无法检查出这是错误的数据。 **

**解决方案**

**传输之前先使用MD5加密数据获得摘要，跟数据一起发送到服务端，服务端接收之后对数据也进行MD5加密，如果加密结果和摘要一致，则认为没有问题**

## 61、UDP是什么？

**提供****无连接**的，尽最大努力的数据传输服务（**不保证数据传输的可靠性**）。

## 62、TCP和UDP的区别

**1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接**

**2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付**

**3、TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的**

**UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）**

**4、每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信**

**5、TCP首部开销20字节;UDP的首部开销小，只有8个字节**

**6、TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道**

**7、UDP是面向报文的，发送方的UDP对应用层交下来的报文，不合并，不拆分，只是在其上面加上首部后就交给了下面的网络层，论应用层交给UDP多长的报文，它统统发送，一次发送一个。而对接收方，接到后直接去除首部，交给上面的应用层就完成任务了。因此，它需要应用层控制报文的大小**

**TCP是面向字节流的，它把上面应用层交下来的数据看成无结构的字节流会发送，可以想象成流水形式的，发送方TCP会将数据放入“蓄水池”（缓存区），等到可以发送的时候就发送，不能发送就等着TCP会根据当前网络的拥塞状态来确定每个报文段的大小。**

## 补充题：封包和拆包你听说过吗？它是基于TCP还是UDP的？

**封包和拆包都是基于TCP的概念。因为TCP是无边界的流传输，所以需要对TCP进行封包和拆包，确保发送和接收的数据不粘连。**

* **封包：封包就是在发送数据报的时候为每个TCP数据包加上一个包头，将数据报分为包头和包体两个部分。包头是一个固定长度的结构体，里面包含该数据包的总长度。**
* **拆包：接收方在接收到报文后提取包头中的长度信息进行截取。**

## 63、UDP的特点有哪些（附赠TCP的特点）？

* **UDP是****无连接的**；
* **UDP使用****尽最大努力交付**，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）；
* **UDP是****面向报文**的；
* **UDP****没有拥塞控制**，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）；
* **UDP****支持一对一、一对多、多对一和多对多**的交互通信；
* **UDP的****首部开销小**，只有8个字节，比TCP的20个字节的首部要短。

**那么，再说一次TCP的特点：**

* **TCP是面向连接的**。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）；
* **每一条TCP连接只能有两个端点，每一条TCP连接只能是点对点的（****一对一**）；
* **TCP****提供可靠交付的服务**。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达；
* **TCP****提供全双工通信**。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据；
* **面向字节流**。TCP中的“流”（stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。

## 64、TCP对应的应用层协议

**FTP：定义了文件传输协议，使用21端口.**
**Telnet：它是一种用于远程登陆的端口,23端口**
**SMTP：定义了简单邮件传送协议，服务器开放的是25号端口。**
**POP3：它是和SMTP对应，POP3用于接收邮件。**

## 65、UDP对应的应用层协议

**DNS：用于域名解析服务，用的是53号端口**
**SNMP：简单网络管理协议，使用161号端口**
**TFTP(Trival File Transfer Protocal)：简单文件传输协议，69**

## 66、数据链路层常见协议？可以说一下吗？

| **协议** | **名称**             | **作用**                                                                                                               |
| -------------- | -------------------------- | ---------------------------------------------------------------------------------------------------------------------------- |
| **ARP**  | **地址解析协议**     | **根据IP地址获取物理地址**                                                                                             |
| **RARP** | **反向地址转换协议** | **根据物理地址获取IP地址**                                                                                             |
| **PPP**  | **点对点协议**       | **主要是用来通过拨号或专线方式建立点对点连接发送数据，使其成为各种主机、网桥和路由器之间简单连接的一种共通的解决方案** |

## 67、Ping命令基于哪一层协议的原理是什么？

**ping命令基于网络层的命令，是基于ICMP协议工作的。**

## 68、在进行UDP编程的时候，一次发送多少bytes好?

**当然,这个没有唯一答案，相对于不同的系统,不同的要求,其得到的答案是不一样的。**

**我这里仅对像ICQ一类的发送聊天消息的情况作分析，对于其他情况，你或许也能得到一点帮助:首先,我们知道,TCP/IP通常被认为是一个四层协议系统,包括链路层,网络层,运输层,应用层.UDP属于运输层,**

**下面我们由下至上一步一步来看:以太网(Ethernet)数据帧的长度必须在46-1500字节之间,这是由以太网的物理特性决定的.这个1500字节被称为链路层的MTU(最大传输单元).但这并不是指链路层的长度被限制在1500字节,其实这这个MTU指的是链路层的数据区.并不包括链路层的首部和尾部的18个字节.**

**所以,事实上,这个1500字节就是网络层IP数据报的长度限制。因为IP数据报的首部为20字节,所以IP数据报的数据区长度最大为1480字节.而这个1480字节就是用来放TCP传来的TCP报文段或UDP传来的UDP数据报的.又因为UDP数据报的首部8字节,所以UDP数据报的数据区最大长度为1472字节.这个1472字节就是我们可以使用的字节数。**

**当我们发送的UDP数据大于1472的时候会怎样呢？**
**这也就是说IP数据报大于1500字节,大于MTU.这个时候发送方IP层就需要分片(fragmentation).**
**把数据报分成若干片,使每一片都小于MTU.而接收方IP层则需要进行数据报的重组.**
**这样就会多做许多事情,而更严重的是,由于UDP的特性,当某一片数据传送中丢失时,接收方便**
**无法重组数据报.将导致丢弃整个UDP数据报。**

**因此,在普通的局域网环境下，我建议将UDP的数据控制在1472字节以下为好.**

**进行Internet编程时则不同,因为Internet上的路由器可能会将MTU设为不同的值.**
**如果我们假定MTU为1500来发送数据的,而途经的某个网络的MTU值小于1500字节,那么系统将会使用一系列的机**
**制来调整MTU值,使数据报能够顺利到达目的地,这样就会做许多不必要的操作.**

**鉴于Internet上的标准MTU值为576字节,所以我建议在进行Internet的UDP编程时.**
**最好将UDP的数据长度控件在548字节(576-8-20)以内**

## 69、TCP 利用滑动窗口实现流量控制的机制？

> **流量控制是为了控制发送方发送速率，保证接收方来得及接收。TCP 利用滑动窗口实现流量控制。**

**TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着****接收方还有多大的缓冲区可以用于接收数据**。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据。

> **例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。**

## 70、可以解释一下RTO，RTT和超时重传分别是什么吗？

* **超时重传：发送端发送报文后若长时间未收到确认的报文则需要重发该报文。可能有以下几种情况：**
  * **发送的数据没能到达接收端，所以对方没有响应。**
  * **接收端接收到数据，但是ACK报文在返回过程中丢失。**
  * **接收端拒绝或丢弃数据。**
* **RTO：从上一次发送数据，因为长期没有收到ACK响应，到下一次重发之间的时间。就是重传间隔。**
  * **通常每次重传RTO是前一次重传间隔的两倍，计量单位通常是RTT。例：1RTT，2RTT，4RTT，8RTT......**
  * **重传次数到达上限之后停止重传。**
* **RTT：数据从发送到接收到对方响应之间的时间间隔，即数据报在网络中一个往返用时。大小不稳定。**

## 71、XSS攻击是什么？（低频）

**跨站点脚本攻击，指攻击者通过篡改网页，嵌入恶意脚本程序，在用户浏览网页时，控制用户浏览器进行恶意操作的一种攻击方式。如何防范XSS攻击**
**1）前端，服务端，同时需要字符串输入的长度限制。**
**2）前端，服务端，同时需要对HTML转义处理。将其中的”<”,”>”等特殊字符进行转义编码。**
**防 XSS 的核心是必须对输入的数据做过滤处理。**

## 72、CSRF攻击？你知道吗？

**跨站点请求伪造，指攻击者通过跨站请求，以合法的用户的身份进行非法操作。可以这么理解CSRF攻击：攻击者盗用你的身份，以你的名义向第三方网站发送恶意请求。CRSF能做的事情包括利用你的身份发邮件，发短信，进行交易转账，甚至盗取账号信息。**

## 73、如何防范CSRF攻击

**安全框架**，例如Spring Security。**
****token机制**。在HTTP请求中进行token验证，如果请求中没有token或者token内容不正确，则认为CSRF攻击而拒绝该请求。**
****验证码**。通常情况下，验证码能够很好的遏制CSRF攻击，但是很多情况下，出于用户体验考虑，验证码只能作为一种辅助手段，而不是最主要的解决方案。**
****referer识别**。在HTTP Header中有一个字段Referer，它记录了HTTP请求的来源地址。如果Referer是其他网站，就有可能是CSRF攻击，则拒绝该请求。但是，服务器并非都能取到Referer。很多用户出于隐私保护的考虑，限制了Referer的发送。在某些情况下，浏览器也不会发送Referer，例如HTTPS跳转到HTTP。**
**1）验证请求来源地址；**
**2）关键操作添加验证码；**
**3）在请求地址添加 token 并验证。

## 74、文件上传漏洞是如何发生的？你有经历过吗？

**文件上传漏洞，指的是用户上传一个可执行的脚本文件，并通过此脚本文件获得了执行服务端命令的能力。**
**许多第三方框架、服务，都曾经被爆出文件上传漏洞，比如很早之前的Struts2，以及富文本编辑器等等，可被攻击者上传恶意代码，有可能服务端就被人黑了。**

## 75、如何防范文件上传漏洞

**文件上传的目录设置为不可执行。**

**1）判断文件类型。在判断文件类型的时候，可以结合使用MIME Type，后缀检查等方式。因为对于上传文件，不能简单地通过后缀名称来判断文件的类型，因为攻击者可以将可执行文件的后缀名称改为图片或其他后缀类型，诱导用户执行。**

**2）对上传的文件类型进行白名单校验，只允许上传可靠类型。**

**3）上传的文件需要进行重新命名，使攻击者无法猜想上传文件的访问路径，将极大地增加攻击成本，同时向shell.php.rar.ara这种文件，因为重命名而无法成功实施攻击。**

**4）限制上传文件的大小。**

**5）单独设置文件服务器的域名。**

## 76、拥塞控制原理听说过吗？

* **拥塞控制目的是防止数据过多注入到网络中导致网络资源（路由器、交换机等）过载。因为拥塞控制涉及网络链路全局，所以属于全局控制。控制拥塞使用拥塞窗口。**
* **TCP拥塞控制算法：**
  * **慢开始 & 拥塞避免：先试探网络拥塞程度再逐渐增大拥塞窗口。假设窗口长度为d，收到一个确认就加1，正好收到了d个确认，所以一共加d，正好是翻倍，直到达到阀值ssthresh，这部分是慢开始过程。达到阀值后每次以一个MSS为单位增长拥塞窗口大小，当发生拥塞（超时未收到确认），将阀值减为原先一半，继续执行增加，这个过程为拥塞避免。**
  * **快速重传 & 快速恢复：略。**
  * **最终拥塞窗口会收敛于稳定值。**

## 77、如何区分流量控制和拥塞控制？

* **流量控制属于通信双方协商；拥塞控制涉及通信链路全局。**
* **流量控制需要通信双方各维护一个发送窗、一个接收窗，对任意一方，接收窗大小由自身决定，发送窗大小由接收方响应的TCP报文段中窗口值确定；拥塞控制的拥塞窗口大小变化由试探性发送一定数据量数据探查网络状况后而自适应调整。**
* **实际最终发送窗口 = min{流控发送窗口，拥塞窗口}。**

## 78、常见的HTTP状态码有哪些？

| **状态码** | **类别**                             | **含义**                       |
| ---------------- | ------------------------------------------ | ------------------------------------ |
| **1XX**    | **Informational（信息性状态码）**    | **接收的请求正在处理**         |
| **2XX**    | **Success（成功状态码）**            | **请求正常处理完毕**           |
| **3XX**    | **Redirection（重定向状态码）**      | **需要进行附加操作以完成请求** |
| **4XX**    | **Client Error（客户端错误状态码）** | **服务器无法处理请求**         |
| **5XX**    | **Server Error（服务器错误状态码）** | **服务器处理请求出**           |

### 1xx 信息

**100 Continue** ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。

### 2xx 成功

* **200 OK**
* **204 No Content** ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。
* **206 Partial Content** ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。

### 3xx 重定向

* **301 Moved Permanently** ：永久性重定向
* **302 Found** ：临时性重定向
* **303 See Other** ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。
* **304 Not Modified** ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。
* **307 Temporary Redirect** ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。

### 4xx 客户端错误

* **400 Bad Request** ：请求报文中存在语法错误。
* **401 Unauthorized** ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。
* **403 Forbidden** ：请求被拒绝。
* **404 Not Found**

### 5xx 服务器错误

* **500 Internal Server Error** ：服务器正在执行请求时发生错误。
* **503 Service Unavailable** ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。

## 79、服务器出现大量close_wait的连接的原因是什么？有什么解决方法？

**close_wait状态是在TCP四次挥手的时候收到FIN但是没有发送自己的FIN时出现的，服务器出现大量close_wait状态的原因有两种：**

* **服务器内部业务处理占用了过多时间，都没能处理完业务；或者还有数据需要发送；或者服务器的业务逻辑有问题，没有执行close()方法**
* **服务器的父进程派生出子进程，子进程继承了socket，收到FIN的时候子进程处理但父进程没有处理该信号，导致socket的引用不为0无法回收**

**处理方法：**

* **停止应用程序**
* **修改程序里的bug**

## 80、一台机器能够使用的端口号上限是多少，是否可以修改？如果想要用的端口超过这个限制怎么办？

**65536.因为TCP的报文头部中源端口号和目的端口号的长度是16位，也就是可以表示2^16=65536个不同端口号，因此TCP可供识别的端口号最多只有65536个。但是由于0到1023是知名服务端口，所以实际上还要少1024个端口号。**

**而对于服务器来说，可以开的端口号与65536无关，其实是受限于Linux可以打开的文件数量，并且可以通过MaxUserPort来进行配置。**

## 81、简述静态路由和动态路由

1. 静态路由是由系统管理员设计与构建的路由表规定的路由。适用于网关数量有限的场合，且网络拓朴结构不经常变化的网络。其缺点是不能动态地适用网络状况的变化，当网络状况变化后必须由网络管理员修改路由表。
2. 动态路由是由路由选择协议而动态构建的，路由协议之间通过交换各自所拥有的路由信息实时更新路由表的内容。动态路由可以自动学习网络的拓朴结构，并更新路由表。其缺点是路由广播更新信息将占据大量的网络带宽。

## 82、说说有哪些路由协议，都是如何更新的

1. 路由可分为静态&动态路由。静态路由由管理员手动维护；动态路由由路由协议自动维护。
   路由选择算法的必要步骤：
   1）向其它路由器传递路由信息；
   2）接收其它路由器的路由信息；
   3）根据收到的路由信息计算出到每个目的网络的最优路径，并由此生成路由选择表；
   4）根据网络拓扑的变化及时的做出反应，调整路由生成新的路由选择表，同时把拓扑变化以路由 信息的形式向其它路由器宣告。
   两种主要算法：距离向量法（Distance Vector Routing）和链路状态算法（Link-State Routing）。
   由此可分为距离矢量（如：RIP、IGRP、EIGRP）&链路状态路由协议（如：OSPF、IS-IS）。 路由协议是路由器之间实现路由信息共享的一种机制，它允许路由器之间相互交换和维护各 自的路由表。当一台路由器的路由表由于某种原因发生变化时，它需要及时地将这一变化通 知与之相连接的其他路由器，以保证数据的正确传递。路由协议不承担网络上终端用户之间 的数据传输任务。
2. 1）RIP 路由协议：RIP 协议最初是为 Xerox 网络系统的 Xerox parc 通用协议而设计的，是 Internet 中常用的 路由协议。RIP 采用距离向量算法，即路由器根据距离选择路由，所以也称为距离向量协议。 路由器收集所有可到达目的地的不同路径，并且保存有关到达每个目的地的最少站点数的路 径信息，除到达目的地的最佳路径外，任何其它信息均予以丢弃。同时路由器也把所收集的 路由信息用 RIP 协议通知相邻的其它路由器。这样，正确的路由信息逐渐扩散到了全网。RIP 使用非常广泛，它简单、可靠，便于配置。但是 RIP 只适用于小型的同构网络，因 为它允许的最大站点数为 15，任何超过 15 个站点的目的地均被标记为不可达。而且 RIP 每 隔 30s 一次的路由信息广播也是造成网络的广播风暴的重要原因之一。
   2）OSPF 路由协议：0SPF 是一种基于链路状态的路由协议，需要每个路由器向其同一管理域的所有其它路 由器发送链路状态广播信息。在 OSPF 的链路状态广播中包括所有接口信息、所有的量度和 其它一些变量。利用 0SPF 的路由器首先必须收集有关的链路状态信息，并根据一定的算法 计算出到每个节点的最短路径。而基于距离向量的路由协议仅向其邻接路由器发送有关路由 更新信息。与 RIP 不同，OSPF 将一个自治域再划分为区，相应地即有两种类型的路由选择方式： 当源和目的地在同一区时，采用区内路由选择；当源和目的地在不同区时，则采用区间路由 选择。这就大大减少了网络开销，并增加了网络的稳定性。当一个区内的路由器出了故障时 并不影响自治域内其它区路由器的正常工作，这也给网络的管理、维护带来方便。
   3）BGP 和 BGP4 路由协议：BGP 是为 TCP／IP 互联网设计的外部网关协议，用于多个自治域之间。它既不是基于纯 粹的链路状态算法，也不是基于纯粹的距离向量算法。它的主要功能是与其它自治域的 BGP 交换网络可达信息。各个自治域可以运行不同的内部网关协议。BGP 更新信息包括网络号／ 自治域路径的成对信息。自治域路径包括到达某个特定网络须经过的自治域串，这些更新信 息通过 TCP 传送出去，以保证传输的可靠性。为了满足 Internet 日益扩大的需要，BGP 还在不断地发展。在最新的 BGP4 中，还可以 将相似路由合并为一条路由。
   4）IGRP 和 EIGRP 协议：EIGRP 和早期的 IGRP 协议都是由 Cisco 发明，是基于距离向量算法的动态路由协议。 EIGRP(Enhanced Interior Gateway Routing Protocol)是增强版的 IGRP 协议。它属于动态内部网 关路由协议，仍然使用矢量－距离算法。但它的实现比 IGRP 已经有很大改进，其收敛特性 和操作效率比 IGRP 有显著的提高。它的收敛特性是基于 DUAL ( Distributed Update Algorithm ) 算法的。DUAL 算法使得路径 在路由计算中根本不可能形成环路。它的收敛时间可以与已存在的其他任何路由协议相匹敌
   Enhanced IGRP 与其它路由选择协议之间主要区别包括：收敛宽速（Fast Convergence）、 支持变长子网掩模（Subnet Mask）、局部更新和多网络层协议。执行 Enhanced IGRP 的路由 器存储了所有其相邻路由表，以便于它能快速利用各种选择路径（Alternate Routes）。如果没有合适路径，Enhanced IGRP 查询其邻居以获取所需路径。直到找到合适路径，EnhancedIGRP 查询才会终止，否则一直持续下去。
   EIGRP 不作周期性更新。取而代之，当路径度量标准改变时，Enhanced IGRP 只发送局 部更新（Partial Updates）信息。局部更新信息的传输自动受到限制，从而使得只有那些需 要信息的路由器才会更新。基于以上这两种性能，因此 Enhanced IGRP 损耗的带宽比 IGRP 少得多。

## 83、简述网关的作用是什么，同一网段的主机如何通信

1. 网关即网络中的关卡，我们的互联网是一个一个的局域网、城域网、等连接起来的，在连接点上就是一个一个网络的关卡，即我们的网关，他是保证网络互连的，翻译和转换，使得不同的网络体系能够进行。
2. 网内通信，即通信双方都位处同一网段中，数据传输无需经过路由器(或三层交换机)，即可由本网段自主完成。
   假设发送主机的ARP表中并无目的主机对应的表项，则发送主机会以目的主机IP地址为内容，广播ARP请求以期获知目的主机MAC地址，并通过交换机(除到达端口之外的所有端口发送，即洪泛(Flooding))向全网段主机转发，而只有目的主机接收到此ARP请求后会将自己的MAC地址和IP地址装入ARP应答后将其回复给发送主机，发送主机接收到此ARP应答后，从中提取目的主机的MAC地址，并在其ARP表中建立目的主机的对应表项(IP地址到MAC地址的映射)，之后即可向目的主机发送数据，将待发送数据封装成帧，并通过二层设备(如交换机)转发至本网段内的目的主机，自此完成通信。

## 84、说一说 TCP 的 keepalive，以及和 HTTP 的 keepalive 的区别？

1. **HTTP Keep-Alive**
   在http早期，每个http请求都要求打开一个tpc socket连接，并且使用一次之后就断开这个tcp连接。使用keep-alive可以改善这种状态，即在一次TCP连接中可以持续发送多份数据而不会断开连接。通过使用keep-alive机制，可以减少tcp连接建立次数，也意味着可以减少TIME_WAIT状态连接，以此提高性能和提高httpd服务器的吞吐率(更少的tcp连接意味着更少的系统内核调用,socket的accept()和close()调用)。但是，keep-alive并不是免费的午餐,长时间的tcp连接容易导致系统资源无效占用。配置不当的keep-alive，有时比重复利用连接带来的损失还更大。所以，正确地设置keep-alive timeout时间非常重要。
2. **TCP KEEPALIVE**
   链接建立之后，如果应用程序或者上层协议一直不发送数据，或者隔很长时间才发送一次数据，当链接很久没有数据报文传输时如何去确定对方还在线，到底是掉线了还是确实没有数据传输，链接还需不需要保持，这种情况在TCP协议设计中是需要考虑到的。TCP协议通过一种巧妙的方式去解决这个问题，当超过一段时间之后，TCP自动发送一个数据为空的报文给对方，如果对方回应了这个报文，说明对方还在线，链接可以继续保持，如果对方没有报文返回，并且重试了多次之后则认为链接丢失，没有必要保持链接。
3. TCP的keepalive机制和HTTP的keep-alive机制是说的完全不同的两个东西，tcp的keepalive是在ESTABLISH状态的时候，双方如何检测连接的可用行。而http的keep-alive说的是如何避免进行重复的TCP三次握手和四次挥手的环节。

## 85、简述 TCP 协议的延迟 ACK 和累计应答

1. 延迟应答指的是：TCP在接收到对端的报文后，并不会立即发送ack，而是等待一段时间发送ack，以便将ack和要发送的数据一块发送。当然ack不能无限延长，否则对端会认为包超时而造成报文重传。linux采用动态调节算法来确定延时的时间。
2. 累计应答指的是：为了保证**顺序性**，每一个包都有一个**ID**（序号），在建立连接的时候，会商定起始的ID是多少，然后按照ID一个个发送。而为了保证不丢包，对应发送的包都要进行应答，但不是一个个应答，而是会**应答某个之前的ID**，该模式称为**累计应答**

## 86、说说 TCP 如何加速一个大文件的传输

1. 建连优化：TCP 在建立连接时，如果丢包，会进入重试，重试时间是 1s、2s、4s、8s 的指数递增间隔，缩短定时器可以让 TCP 在丢包环境建连时间更快，非常适用于高并发短连接的业务场景。
2. 平滑发包：在 RTT 内均匀发包，规避微分时间内的流量突发，尽量避免瞬间拥塞
3. 丢包预判：有些网络的丢包是有规律性的，例如每隔一段时间出现一次丢包，例如每次丢包都连续丢几个等，如果程序能自动发现这个规律（有些不明显），就可以针对性提前多发数据，减少重传时间、提高有效发包率。
4. RTO 探测：若始终收不到 ACK 报文，则需要触发 RTO 定时器。RTO 定时器一般都时间非常长，会浪费很多等待时间，而且一旦 RTO，CWND 就会骤降（标准 TCP），因此利用 Probe 提前与 RTO 去试探，可以规避由于 ACK 报文丢失而导致的速度下降问题。
5. 带宽评估：通过单位时间内收到的 ACK 或 SACK 信息可以得知客户端有效接收速率，通过这个速率可以更合理的控制发包速度。
6. 带宽争抢：有些场景（例如合租）是大家互相挤占带宽的，假如你和室友各 1Mbps 的速度看电影，会把 2Mbps 出口占满，而如果一共有 3 个人看，则每人只能分到 1/3。若此时你的流量流量达到 2Mbps，而他俩还都是 1Mbps，则你至少仍可以分到 2/(2+1+1) * 2Mbps = 1Mbps 的 50% 的带宽，甚至更多，代价就是服务器侧的出口流量加大，增加成本。（TCP 优化的本质就是用带宽换用户体验感）

## 87、服务器怎么判断客户端断开了连接

1. 检测连接是否丢失的方法大致有两种：**keepalive**和**heart-beat**
2. （tcp内部机制）采用keepalive，它会先要求此连接一定时间没有活动（一般是几个小时），然后发出数据段，经过多次尝试后（每次尝试之间也有时间间隔），如果仍没有响应，则判断连接中断。可想而知，整个**周期需要很长**的时间。
3. （应用层实现）一个简单的heart-beat实现一般测试连接是否中断采用的时间间隔都比较短，可以**很快的决定连接是否中断**。并且，由于是在应用层实现，因为可以自行决定当判断连接中断后应该采取的行为，而keepalive在判断连接失败后只会将连接丢弃。

## 88、说说 HTTP 中的 referer 头的作用

1. HTTP Referer是header的一部分，当浏览器向web服务器发送请求的时候，一般会带上Referer，告诉服务器该网页是从哪个页面链接过来的，服务器因此可以获得一些信息用于处理。
2. 防盗链。假如在[www.google.com](https://www.nowcoder.com/issue/www.google.com)里有一个 `[www.baidu.com](https://www.nowcoder.com/issue/www.baidu.com)`链接，那么点击进入这个 `[www.baidu.com](https://www.nowcoder.com/issue/www.baidu.com)`，它的header信息里就有：Referer= [http://www.google.com](http://www.google.com/)
   只允许我本身的网站访问本身的图片服务器，假如域是[www.google.com](http://www.google.com/)，那么图片服务器每次取到Referer来判断一下域名是不是[www.google.com](http://www.google.com/)，如果是就继续访问，不是就拦截。
   将这个http请求发给服务器后，如果服务器要求必须是某个地址或者某几个地址才能访问，而你发送的referer不符合他的要求，就会拦截或者跳转到他要求的地址，然后再通过这个地址进行访问。
3. 防止恶意请求
   比如静态请求是*.html结尾的，动态请求是*.shtml，那么由此可以这么用，所有的*.shtml请求，必须Referer为我自己的网站。
4. 空Referer
   **定义**：Referer头部的内容为空，或者，一个HTTP请求中根本不包含Referer头部（一个请求并不是由链接触发产生的）
   直接在浏览器的地址栏中输入一个资源的URL地址，那么这种请求是不会包含Referer字段的，因为这是一个“凭空产生”的HTTP请求，并不是从一个地方链接过去的。
   那么在防盗链设置中，允许空Referer和不允许空Referer有什么区别？
   允许Referer为空，意味着你允许比如浏览器直接访问。
5. 防御CSRF
   比对HTTP 请求的来源地址，如果Referer中的地址是安全可信任的地址，那么就放行
